{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnosis\n",
    "\n",
    "While the purpose of Flaredown for it's users isn't about diagnosis, we would be remiss if we ignored the fact that we have a very solid training set for a system to perform diagnosis.  We will reshape the data so that our features are one-hotted symptoms, and we will predict on condition.\n",
    "\n",
    "There are a lot of algorithms out there that take a list of self reported symptoms and attempt a diagnosis.  But the depth and breadth of the ever-growing Flaredown data may provide new oppertunities for this task, especially since in the future Flaredown may collect any number of additional variables.\n",
    "\n",
    "I do recommend giving this some time before it's used.  At this time (Aug 22, 2016) the data only describes about 900 conditions.  For a diagnosis engine to be useful it is likely to require a huge breadth of conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "df = pd.read_csv(\"flaredown_trackable_data_080316.csv\")\n",
    "df['checkin_date'] = pd.to_datetime(df['checkin_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#reshape and one-hot the symptoms\n",
    "symptoms = pd.get_dummies(df[(df['trackable_type'] == \"Symptom\") & (df['trackable_value'] != 0)], columns=['trackable_name'])\n",
    "symptoms = symptoms.drop(['trackable_id', 'trackable_type', 'trackable_value'], axis=1)\n",
    "\n",
    "def numericOr(x):\n",
    "    if 1 in x.values:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "symptoms = symptoms.groupby(['user_id', 'checkin_date']).agg(numericOr).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "def combineConditions(x):\n",
    "    return set(x)\n",
    "\n",
    "def makeList(x):\n",
    "    return list(x)\n",
    "\n",
    "newdf = df[df['trackable_type'] == 'Condition'].groupby(['user_id', 'checkin_date'])['trackable_name'].agg(combineConditions).reset_index()\n",
    "newdf = newdf.merge(symptoms, on=['user_id','checkin_date'])\n",
    "\n",
    "#newdf = newdf.drop_duplicates().drop(['user_id','checkin_date','trackable_id','trackable_type', 'trackable_value'], axis=1)\n",
    "newdf = newdf.drop(['user_id','checkin_date'], axis=1)\n",
    "X = newdf.drop('trackable_name', axis=1)\n",
    "Y = newdf['trackable_name'].apply(makeList)  # each row of Y is a list, because this is a multilabel problem\n",
    "Y = MultiLabelBinarizer().fit_transform(Y)  \n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A note about model selection\n",
    "\n",
    "It is important to note that in this case Y is a matrix.  This is an example of multi-label classification, in that each user may be suffering from any number of conditions.  Because of this, a classifier that can handle multi-label must be used.  Fortunately, sklearn has several options for this including:\n",
    "\n",
    "Decision Trees, Random Forests, Nearest Neighbors, Ridge Regression\n",
    "\n",
    "TODO should try all of the above\n",
    "\n",
    "### Resources\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_multilabel_classification.html#sklearn.datasets.make_multilabel_classification\n",
    "\n",
    "http://scikit-learn.org/stable/modules/multiclass.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "#This block uses SVM, which slows way down for problems of this size, skip this block if you're in a hurry\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = OneVsRestClassifier(SVC(kernel='poly'))\n",
    "clf.fit(X_train, Y_train)\n",
    "Y_pred = clf.predict(X_test)\n",
    "print Y_test\n",
    "print Y_pred\n",
    "print accuracy_score(Y_test, Y_pred)  #TODO accuracy score doesn't paint a complete picture for multilabel, should use something else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Blah random forest\n",
    "#TODO Can we get some multilabel Gradient Boosting up in here?\n",
    "from sklearn.ensemble import RandomForest\n",
    "rf = RandomForestClassifier(n_estimators=10, criterion='gini', max_depth=3)\n",
    "rf.fit(X_train, Y_train)\n",
    "Y_pred = rf.predict(X_test)\n",
    "print accuracy_score(Y_test, Y_pred)\n",
    "print Y_test\n",
    "print Y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
