{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnosis\n",
    "\n",
    "While the purpose of Flaredown for it's users isn't about diagnosis, we would be remiss if we ignored the fact that we have a very solid training set for a system to perform diagnosis.  We will reshape the data so that our features are one-hotted symptoms, and we will predict on condition.\n",
    "\n",
    "There are a lot of algorithms out there that take a list of self reported symptoms and attempt a diagnosis.  But the depth and breadth of the ever-growing Flaredown data may provide new oppertunities for this task, especially since in the future Flaredown may collect any number of additional variables.\n",
    "\n",
    "I do recommend giving this some time before it's used.  At this time (Aug 22, 2016) the data only describes about 900 conditions.  For a diagnosis engine to be useful it is likely to require a huge breadth of conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import label_ranking_average_precision_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "df = pd.read_csv(\"flaredown_trackable_data_080316.csv\")\n",
    "df['checkin_date'] = pd.to_datetime(df['checkin_date'])\n",
    "\n",
    "def combineConditions(x):\n",
    "    return set(x)\n",
    "\n",
    "def makeList(x):\n",
    "    return list(x)\n",
    "\n",
    "def numericOr(x):\n",
    "    if 1 in x.values:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def reshapeSymptoms(df):\n",
    "    #reshape and one-hot the symptoms\n",
    "\n",
    "    symptoms = pd.get_dummies(df[(df['trackable_type'] == \"Symptom\") & (df['trackable_value'] != 0)], columns=['trackable_name'])\n",
    "    symptoms = symptoms.drop(['trackable_id', 'trackable_type', 'trackable_value'], axis=1)\n",
    "    symptoms = symptoms.groupby(['user_id', 'checkin_date']).agg(numericOr).reset_index()\n",
    "    return symptoms\n",
    "    \n",
    "def createXY(df, symptoms):\n",
    "    newdf = df[df['trackable_type'] == 'Condition'].groupby(['user_id', 'checkin_date'])['trackable_name'].agg(combineConditions).reset_index()\n",
    "    newdf = newdf.merge(symptoms, on=['user_id','checkin_date'])\n",
    "\n",
    "    #newdf = newdf.drop_duplicates().drop(['user_id','checkin_date','trackable_id','trackable_type', 'trackable_value'], axis=1)\n",
    "    newdf = newdf.drop(['user_id','checkin_date'], axis=1)\n",
    "    X = newdf.drop('trackable_name', axis=1)\n",
    "    Y = newdf['trackable_name'].apply(makeList)  # each row of Y is a list, because this is a multilabel problem\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    Y = mlb.fit_transform(Y)  \n",
    "    return train_test_split(X, Y, test_size=0.2, random_state=42)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "symptoms = reshapeSymptoms(df)\n",
    "X_train, X_test, Y_train, Y_test = createXY(df, symptoms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A note about model selection\n",
    "\n",
    "It is important to note that in this case Y is a matrix.  This is an example of multi-label classification, in that each user may be suffering from any number of conditions.  Because of this, a classifier that can handle multi-label must be used.  Fortunately, sklearn has several options for this including:\n",
    "\n",
    "Decision Trees, Random Forests, Nearest Neighbors, Ridge Regression\n",
    "\n",
    "TODO should try all of the above - but the one-hotted data is waaay sparse, are any of those really going to cut it?  Maybe need to think about PCA here before trying to classify\n",
    "\n",
    "### Resources\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_multilabel_classification.html#sklearn.datasets.make_multilabel_classification\n",
    "\n",
    "http://scikit-learn.org/stable/modules/multiclass.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def meanF1(y, pred):\n",
    "    row_f1 = np.zeros((y.shape[0]))\n",
    "    for k in range(y.shape[0]):\n",
    "        tp = (pred[k] * y[k]).sum()\n",
    "        fp = (pred[k] > y[k]).sum()\n",
    "        fn = (pred[k] < y[k]).sum()\n",
    "        precision = tp/(tp + fp + 1e-9)\n",
    "        recall = tp/(tp + fn + 1e-9)\n",
    "        row_f1[k] = 2 * precision * recall / (precision + recall + 1e-9)\n",
    "    return np.mean(row_f1)\n",
    "\n",
    "def scorePredictions(X_train, X_test, Y_train, Y_test):\n",
    "    rf = OneVsRestClassifier(RandomForestClassifier(n_estimators=10, criterion='gini', max_depth=3))\n",
    "    rf.fit(X_train, Y_train)\n",
    "    Y_pred = rf.predict(X_test)\n",
    "    print meanF1(Y_test, Y_pred)\n",
    "    #print label_ranking_average_precision_score(Y_test, Y_pred)\n",
    "    print mlb.inverse_transform(Y_test)[1]\n",
    "    print mlb.inverse_transform(Y_pred)[1]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.109695248449\n",
      "('Celiac disease', 'Collagenous colitis', 'Complex partial seizures', 'Fatigue', 'GERD', 'Headaches', 'Interstitial cystitis', 'Lyme disease', 'Osteoarthritis', 'Osteoporosis', 'Scleroderma')\n",
      "('Celiac disease', 'Complex partial seizures', 'Fatigue', 'GERD', 'Headaches', 'Lyme disease', 'Osteoarthritis', 'Scleroderma')\n"
     ]
    }
   ],
   "source": [
    "scorePredictions(X_train, X_test, Y_train, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "OK first off, that score is not pretty.  1 is the optimal score for that metric.  At least it will be easy to beat the benchmark...\n",
    "\n",
    "Also, those warnings are a legit problem.  What's happening is, some conditions only appear in the data once, and thus they can't be represented in both the training and test sets.  I'm going to have to filter out those conditions and not attempt to predict them.  And unfortunately, I'm going to have to not predict on the entire user, since deleting one of their conditions renders the rest of their symptom/condition relationships invalid.  As usual, as the data grows this should become less of a problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting 214 users who have unique condition values\n"
     ]
    }
   ],
   "source": [
    "#Since the original DF is one condition per line, it's easier to filter there and recreate our X and Y\n",
    "def filterCondition(x):\n",
    "    keep = True\n",
    "    for value in x:\n",
    "        if value in onceoffs:\n",
    "            keep = False\n",
    "    return keep\n",
    "\n",
    "condition_counts = df[df['trackable_type'] == 'Condition']['trackable_name'].value_counts()\n",
    "onceoffs = list(condition_counts[condition_counts < 2].keys())\n",
    "#cleandf = df.groupby('user_id').filter(lambda x: x not in onceoffs)\n",
    "cleandf = df.groupby('user_id').filter(filterCondition)\n",
    "print \"deleting \" + str(len(onceoffs)) + \" users who have unique condition values\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.109060572185\n",
      "('Celiac disease', 'Collagenous colitis', 'Complex partial seizures', 'Fatigue', 'GERD', 'Headaches', 'Interstitial cystitis', 'Lyme disease', 'Osteoarthritis', 'Osteoporosis', 'Scleroderma')\n",
      "('Collagenous colitis', 'Complex partial seizures', 'Fatigue', 'GERD', 'Headaches', 'Interstitial cystitis', 'Lyme disease', 'Osteoarthritis', 'Osteoporosis', 'Scleroderma')\n"
     ]
    }
   ],
   "source": [
    "symptoms = reshapeSymptoms(cleandf)\n",
    "X_train, X_test, Y_train, Y_test = createXY(cleandf, symptoms)\n",
    "scorePredictions(X_train, X_test, Y_train, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it's producing some reasonable results, but the score still sucks mightily.\n",
    "\n",
    "In a similar problem, [this guy](https://github.com/davidthaler/Greek_media) had good luck with running his Y through PCA and using a Ridge regressor.  I'm going to give that a try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.451828111003\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "def predict(decision, threshold1, threshold2):\n",
    "    pred = ((decision - threshold1) > 0).astype(float)\n",
    "    max_decision = decision.max(1)\n",
    "    for k in range(pred.shape[0]):\n",
    "        cut = max_decision[k] - threshold2\n",
    "        idx = (decision[k, :] >= cut) \n",
    "        pred[k, idx] = 1\n",
    "    return pred\n",
    "\n",
    "def scoreRidge(pca_comps, thresh1, thresh2, ridge_alpha):\n",
    "    pcaobj = PCA(n_components=pca_comps)  \n",
    "    Y_train_transformed = pcaobj.fit_transform(Y_train)\n",
    "    rig = Ridge(alpha=ridge_alpha) \n",
    "    rig.fit(X_train, Y_train_transformed)\n",
    "\n",
    "    prediction = rig.predict(X_test)\n",
    "    pred = pcaobj.inverse_transform(prediction)\n",
    "    Y_pred = predict(pred,thresh1, thresh2)\n",
    "    return meanF1(Y_test, Y_pred)\n",
    "\n",
    "def predictRidge(pca_comps, thresh1, thresh2, ridge_alpha):\n",
    "    pcaobj = PCA(n_components=pca_comps)  \n",
    "    Y_train_transformed = pcaobj.fit_transform(Y_train)\n",
    "    rig = Ridge(alpha=ridge_alpha) \n",
    "    rig.fit(X_train, Y_train_transformed)\n",
    "\n",
    "    prediction = rig.predict(X_test)\n",
    "    pred = pcaobj.inverse_transform(prediction)\n",
    "    Y_pred = predict(pred,thresh1, thresh2)\n",
    "    return Y_pred\n",
    "\n",
    "#all these hypers are arbitrary, will optimize later if it works out\n",
    "score = scoreRidge(10,0.3,0.1,1)\n",
    "print score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's around 4x better than my benchmark... before even optimizing.  And I only expected around %50 F1 to be possible anyway.\n",
    "\n",
    "Time to optimize.  I'm going to grid search, because ridge regression runs so fast anyways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA Comps 5 thresh1 0.05 thresh2 0.05 ridge_alpha 1 score0.196211012586\n",
      "PCA Comps 5 thresh1 0.1 thresh2 0.05 ridge_alpha 1 score0.289850873118\n",
      "PCA Comps 5 thresh1 0.5 thresh2 0.05 ridge_alpha 1 score0.353871577766\n",
      "PCA Comps 10 thresh1 0.5 thresh2 0.05 ridge_alpha 1 score0.439993263063\n",
      "PCA Comps 15 thresh1 0.5 thresh2 0.05 ridge_alpha 1 score0.503744515188\n",
      "PCA Comps 20 thresh1 0.5 thresh2 0.05 ridge_alpha 1 score0.559917903774\n",
      "PCA Comps 25 thresh1 0.5 thresh2 0.05 ridge_alpha 1 score0.622782453263\n",
      "PCA Comps 30 thresh1 0.5 thresh2 0.05 ridge_alpha 1 score0.659664689019\n"
     ]
    }
   ],
   "source": [
    "def findMaxScore(pca_comps,thresh1s,thresh2s,ridge_alphas):\n",
    "    max_score = 0\n",
    "    for pca_comp in pca_comps:\n",
    "        for thresh1 in thresh1s:\n",
    "            for thresh2 in thresh2s:\n",
    "                for ridge_alpha in ridge_alphas:\n",
    "                    score = scoreRidge(pca_comp,thresh1,thresh2,ridge_alphas)\n",
    "                    if score > max_score:\n",
    "                        max_score = score\n",
    "                        print \"PCA Comps \" + str(pca_comp) + \" thresh1 \" + str(thresh1) + \" thresh2 \" + str(thresh2) + \" ridge_alpha \" + str(ridge_alpha) +\" score\" + str(score)\n",
    "pca_comps = [5,10,15,20,25,30]\n",
    "thresh1s = [0.05,0.1,0.5]\n",
    "thresh2s = [0.05,0.1,0.5]\n",
    "ridge_alphas = [1]\n",
    "findMaxScore(pca_comps,thresh1s,thresh2s,ridge_alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA Comps 35 thresh1 0.5 thresh2 0.01 ridge_alpha 1 score0.681774234408\n",
      "PCA Comps 35 thresh1 0.5 thresh2 0.05 ridge_alpha 1 score0.684301326599\n",
      "PCA Comps 40 thresh1 0.5 thresh2 0.01 ridge_alpha 1 score0.710495957352\n",
      "PCA Comps 45 thresh1 0.5 thresh2 0.01 ridge_alpha 1 score0.728313727167\n",
      "PCA Comps 50 thresh1 0.5 thresh2 0.01 ridge_alpha 1 score0.746364508545\n"
     ]
    }
   ],
   "source": [
    "#Some of the optimal values found were at the max range, so just going to do that again with some higher/lower values\n",
    "\n",
    "pca_comps = [35,40,45,50]\n",
    "thresh1s = [0.5,1,1.5]\n",
    "thresh2s = [0.01,0.05]\n",
    "ridge_alphas = [1]\n",
    "findMaxScore(pca_comps,thresh1s,thresh2s,ridge_alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA Comps 100 thresh1 0.5 thresh2 0.001 ridge_alpha 1 score0.803389862461\n",
      "PCA Comps 100 thresh1 0.5 thresh2 0.01 ridge_alpha 1 score0.80477609451\n",
      "PCA Comps 150 thresh1 0.5 thresh2 0.001 ridge_alpha 1 score0.836694243113\n",
      "PCA Comps 150 thresh1 0.5 thresh2 0.01 ridge_alpha 1 score0.838125110049\n",
      "PCA Comps 200 thresh1 0.5 thresh2 0.001 ridge_alpha 1 score0.847978972387\n",
      "PCA Comps 200 thresh1 0.5 thresh2 0.01 ridge_alpha 1 score0.849965862481\n",
      "PCA Comps 300 thresh1 0.5 thresh2 0.001 ridge_alpha 1 score0.854075770037\n",
      "PCA Comps 300 thresh1 0.5 thresh2 0.01 ridge_alpha 1 score0.855022029633\n",
      "PCA Comps 400 thresh1 0.5 thresh2 0.001 ridge_alpha 1 score0.856714751009\n",
      "PCA Comps 400 thresh1 0.5 thresh2 0.01 ridge_alpha 1 score0.857671212865\n"
     ]
    }
   ],
   "source": [
    "pca_comps = [100,150,200,300,400]\n",
    "thresh1s = [0.5,0.6,0.7,0.8]\n",
    "thresh2s = [0.001,0.01]\n",
    "ridge_alphas = [1]\n",
    "findMaxScore(pca_comps,thresh1s,thresh2s,ridge_alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA Comps 400 thresh1 0.5 thresh2 0.01 ridge_alpha 1 score0.857671212865\n",
      "PCA Comps 500 thresh1 0.5 thresh2 0.01 ridge_alpha 1 score0.857834038136\n",
      "PCA Comps 600 thresh1 0.5 thresh2 0.01 ridge_alpha 1 score0.858864297086\n"
     ]
    }
   ],
   "source": [
    "pca_comps = [400,500,600,700,800]\n",
    "thresh1s = [0.5]\n",
    "thresh2s = [0.01]\n",
    "ridge_alphas = [1]\n",
    "findMaxScore(pca_comps,thresh1s,thresh2s,ridge_alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA Comps 500 thresh1 0.5 thresh2 0.01 ridge_alpha 1 score0.857834038136\n",
      "PCA Comps 550 thresh1 0.5 thresh2 0.01 ridge_alpha 1 score0.858797344756\n",
      "PCA Comps 600 thresh1 0.5 thresh2 0.01 ridge_alpha 1 score0.858864297086\n",
      "PCA Comps 625 thresh1 0.5 thresh2 0.01 ridge_alpha 1 score0.858936589744\n"
     ]
    }
   ],
   "source": [
    "pca_comps = [500,550,600,625,650]\n",
    "thresh1s = [0.5]\n",
    "thresh2s = [0.01]\n",
    "ridge_alphas = [1]\n",
    "findMaxScore(pca_comps,thresh1s,thresh2s,ridge_alphas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this time there are only 808 classes in Y, and we reduce it to 625.  So PCA isn't reducing that much, but as we can see above it's still providing some great benefits.\n",
    "\n",
    "The final score of 0.8589 is far beyond what I thought would be possible.\n",
    "\n",
    "Finally, lets take a look at what we can do with these results.  The question I'd like to answer is, for the misclassified users, how misclassified were they, and was there something unusual about these users?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_pred = predictRidge(625,0.5,0.01,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "users where we guessed they had a condition that they aren't reporting 281\n",
      "users where we guessed that they didn't have a condition that they are reporting 642\n",
      "users where we guessed different conditions than they are reporting 144\n"
     ]
    }
   ],
   "source": [
    "longer = []\n",
    "shorter = []\n",
    "same = []\n",
    "Y_test_classes = mlb.inverse_transform(Y_test)\n",
    "Y_pred_classes = mlb.inverse_transform(Y_pred)\n",
    "for i in range(len(Y_pred)):\n",
    "    if not (Y_pred[i] == Y_test[i]).all():\n",
    "        if len(Y_pred_classes[i]) > len(Y_test_classes[i]):\n",
    "            longer.append(Y_pred_classes[i])\n",
    "        elif len(Y_pred_classes[i]) < len(Y_test_classes[i]):\n",
    "            shorter.append(Y_pred_classes[i])\n",
    "        else:\n",
    "            same.append(Y_pred_classes[i])\n",
    "print \"users where we guessed they had a condition that they aren't reporting \" + str(len(longer))\n",
    "print \"users where we guessed that they didn't have a condition that they are reporting \" + str(len(shorter))\n",
    "print \"users where we guessed different conditions than they are reporting \" + str(len(same))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Asthma',)\n",
      "('Acne',)\n",
      "('Chronic fatigue syndrome',)\n",
      "(\"Crohn's disease\",)\n",
      "('Chronic fatigue syndrome',)\n",
      "(\"Hashimoto's disease\",)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "misclass_pred = []\n",
    "misclass_test = []\n",
    "misclass_index = []\n",
    "for i in range(len(Y_pred)):\n",
    "    if not (Y_pred[i] == Y_test[i]).all():\n",
    "        if len(Y_pred_classes[i]) == len(Y_test_classes[i]):\n",
    "            misclass_pred.append(Y_pred_classes[i])\n",
    "            misclass_test.append(Y_test_classes[i])\n",
    "            misclass_index.append(i)\n",
    "print misclass_pred[0]\n",
    "print misclass_test[0]\n",
    "            \n",
    "print misclass_pred[1]\n",
    "print misclass_test[1]\n",
    "\n",
    "print misclass_pred[2]\n",
    "print misclass_test[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just looking at these first few, it seems like the errors it's making are highly unrelated conditions.  Lets take a look at the symptoms these users reported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user reports (\"Hashimoto's disease\",)\n",
      "we predict ('Chronic fatigue syndrome',)\n",
      "their symptoms are \n",
      "trackable_name_Dull            1.0\n",
      "trackable_name_Joint pain      1.0\n",
      "trackable_name_Muscle pain     1.0\n",
      "trackable_name_itching face    1.0\n",
      "Name: 4547, dtype: float64\n",
      "\n",
      "\n",
      "user reports ('Ulcerative colitis',)\n",
      "we predict ('Fatigue',)\n",
      "their symptoms are \n",
      "trackable_name_Crying                           1.0\n",
      "trackable_name_Post-op shoulder surgery pain    1.0\n",
      "trackable_name_Shooting pain in legs            1.0\n",
      "trackable_name_Stomach Pain                     1.0\n",
      "Name: 6137, dtype: float64\n",
      "\n",
      "\n",
      "user reports (\"Crohn's disease\",)\n",
      "we predict ('Idiopathic hypersomnia',)\n",
      "their symptoms are \n",
      "trackable_name_Abdominal pain    1.0\n",
      "trackable_name_Anxiety           1.0\n",
      "trackable_name_Self Harm         1.0\n",
      "trackable_name_sleepiness        1.0\n",
      "Name: 5034, dtype: float64\n",
      "\n",
      "\n",
      "user reports ('Arthritis', 'Endometriosis', 'Fibromyalgia')\n",
      "we predict ('Arthritis', 'Chronic pelvic pain', 'Vulvodynia')\n",
      "their symptoms are \n",
      "trackable_name_Abdominal pain           1.0\n",
      "trackable_name_Altered mental status    1.0\n",
      "trackable_name_Ankle pain               1.0\n",
      "trackable_name_Anxiety                  1.0\n",
      "trackable_name_Joint pain               1.0\n",
      "trackable_name_Joint stiffness          1.0\n",
      "trackable_name_Pelvic pain              1.0\n",
      "trackable_name_Rectal bleeding          1.0\n",
      "trackable_name_Rectal pain              1.0\n",
      "trackable_name_Restlessness             1.0\n",
      "trackable_name_Vaginal pain             1.0\n",
      "trackable_name_Weakness                 1.0\n",
      "Name: 16120, dtype: float64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "misclass_X = X_test.iloc[misclass_index,:]\n",
    "\n",
    "def printSymptoms(index):\n",
    "    user = misclass_X.iloc[index,:]\n",
    "    print \"user reports \" + str(misclass_test[index])\n",
    "    print \"we predict \" + str(misclass_pred[index])\n",
    "    print \"their symptoms are \" \n",
    "    print user[user.values==1]\n",
    "    print \"\\n\"\n",
    "\n",
    "printSymptoms(2)\n",
    "printSymptoms(10)\n",
    "printSymptoms(50)\n",
    "printSymptoms(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm not sure how to quantify this result, if anybody has any ideas let me know.  But just looking at these examples by hand, it seems like our predictions tend to make more sense than what they users are reporting!  This gives me high-hopes that even with the current small dataset, we could be making really good recommendations about conditions that a user might want to look into.\n",
    "\n",
    "It's difficult to interpret the results.  Sometimes it seems like the predicted condition should replace the existing condition, but sometimes it seems like it should be added on.\n",
    "The first in this list really stands out for me, as a person suffering from Hashimoto's shouldn't even have symptoms if they're on their meds.  That seems to lend credability to our prediction, as it really seems likely that this user has more going on with their health than just Hashimoto's.\n",
    "The example where we predict 'Idiopathic hypersomnia' is interesting because that user is reporting very little in the way of Crohn's symptoms.  But presumably a person that reports Crohn's has been diagnosed with this by a doctor.  So in general I think it's best to err on the side of caution and not ever suggest that a user's existing condtions are mis-diagnosis.\n",
    "\n",
    "One more point of interest is that these predictions sometimes say interesting things about the conditions that they are predicting.  In the case of the user above that we predicted Idiopathic hypersomnia for, our diagnosis seems to be based on the report of 'self harm'.  Self harm doesn't seem like a symptom that one would normal associate with idiopathic hypersomnia.  And yet, when we look at the data, this symptom is in fact very commonly paired with this condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
